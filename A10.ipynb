{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10\n",
    "Multi-Resolution Analysis\n",
    "\n",
    "\n",
    "1. Freesound Links of Sound Analyzed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) https://www.freesound.org/people/GrowingUp/sounds/254114/\n",
    "\n",
    "2) Band Edges used - (0-1500), (1500,5000), (5000,22050)\n",
    "   Window Sizes - 4096, 2048, 1024\n",
    "   \n",
    "   The sound is a folk like instrument ensemble with percussion and vocal chants. The first band captured the lower frequencies with a higher resolution and the larger 2nd and 3rd bands were able to capture the time resolution better with a smaller window size. This enabled us to hear both the melodies of the vocal ensemble and the time resolution of the percussive hits.\n",
    "   \n",
    "   \n",
    "b) https://www.freesound.org/people/antoinevg/sounds/368000/\n",
    "\n",
    "2) Band Edges used - (0-500), (500,2000), (2000,22050)\n",
    "   Window Sizes - 2048, 1024, 512\n",
    "    \n",
    "   The synth sound is a realy arpeggiated sound that needs really good time resolution for the on/off sound but the timbre of the synth keeps changing. The window sizes are chosen smaller to obtain the stronger time resolution especially in the wide range of 2000-22050 Hz. Using the smaller first two bands enables us to better resolve the really low harmonics (0-500Hz) and also the reasonably higher harmonics upto 2kHz.\n",
    "   \n",
    "   \n",
    "3) A Smaller window is needed for better time resolution but this gives less frequency resolution while a Larger window is needed for better frequency resolution but averaging over a larrger segment in time. The multiresolution analysis obtains a balance of a good time and frequency resolution. This means that the peaks of a harmonic sound will be better resolved and this will help obtain a better HPS and HPR model. Addind many more bands will make it slightly more computationally expensive, since all the frames are now analyzed multiple times based on number of bands. But this is not significantly changed for 3 bands. O(mn) where m is number of bands, n is number of frames.\n",
    "\n",
    "4) We will have better f0 tracking because of better resolved peaks. Sinetracking will become harder implementation wise, because we will need to keep track of sine tracks across bands in measuring freqDistance by accounting for the correct frequency resolution of each bin across the bands. A smaller band will have each bin corresponding to a larger frequency and a larger band will have each bin corresponding to a smaller frequency.\n",
    "\n",
    "5) Other methods of better handling the time and frequency resolution problem would be by using (DWT) a discrete wavelet transform or by using the sparse representations[1] by using a over complete dictionary. Another method could be using deep learning techniques to learn the accurate multi-band lengths across each frame.\n",
    "\n",
    "\n",
    "[1] (BerrÄ±os, Rafael Alvarez. RIO PIEDRAS CAMPUS FACULTY OF NATURAL SCIENCES DEPARTMENT OF MATHEMATICS. Diss. UNIVERSITY OF PUERTO RICO, 2014.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is the Definition of the MultiResolution Analysis method in the SineModel.py\n",
    "## This wont execute by itself. This needs to be added as a method in the SineModel.py in /sms-tools/software/models/\n",
    "\n",
    "def sineModelMultiRes(x, fs, w_k, N_k, t, B_k):\n",
    "        \"\"\"\n",
    "        Analysis/synthesis of a sound using the sinusoidal multiresolution model,\n",
    "        x: input array sound, w_k: an array of three analysis windows, N_k: an array of three sizes of complex spectrum, t: threshold in negative dB, B_k: an array of bandwidths \n",
    "        returns y: output array sound\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        winLengths = np.array([w.size for w in w_k])\n",
    "\n",
    "        Ns = 512                                                # FFT size for synthesis\n",
    "        H = Ns/4                                                # Hop size used for synthesis\n",
    "        hNs = Ns/2                                              # half of synthesis FFT size\n",
    "\n",
    "        maxLength = int(math.floor((np.max(winLengths) + 1)/2.0))\n",
    "        pin = max(hNs,maxLength)\n",
    "        pend = x.size - pin\n",
    "\n",
    "        #fftbuffer = np.zeros(Ns)                                # initialize buffer for FFT\n",
    "        yw = np.zeros(Ns)                                       # initialize output sound frame\n",
    "        y = np.zeros(x.size)                                    # initialize output array\n",
    "        sw = np.zeros(Ns)                                       # initialize synthesis window\n",
    "        ow = triang(2*H)                                        # triangular window\n",
    "        sw[hNs-H:hNs+H] = ow                                    # add triangular window\n",
    "        bh = blackmanharris(Ns)                                 # blackmanharris window\n",
    "        bh = bh / sum(bh)                                       # normalized blackmanharris window\n",
    "        sw[hNs-H:hNs+H] = sw[hNs-H:hNs+H] / bh[hNs-H:hNs+H]     # normalized synthesis window\n",
    "\n",
    "        for w in w_k:\n",
    "                w = w/sum(w)\n",
    "\n",
    "        while pin < pend:\n",
    "\n",
    "                ipfreqTotal = np.array([])\n",
    "                ipmagTotal = np.array([])\n",
    "                ipphaseTotal = np.array([])\n",
    "                for w, N, B in zip(w_k, N_k, B_k):\n",
    "                        fftbuffer = np.zeros(N)\n",
    "                        M = w.size\n",
    "                        hM1 = int(math.floor((M+1)/2))\n",
    "                        hM2 = int(math.floor(M/2))\n",
    "\n",
    "                        x1 = x[pin - hM1 : pin + hM2]\n",
    "                        mX,pX = DFT.dftAnal(x1,w,N)\n",
    "                        ploc = UF.peakDetection(mX, t)\n",
    "                        iploc, ipmag, ipphase = UF.peakInterp(mX,pX,ploc)\n",
    "                        ipfreq = fs*iploc/float(N)\n",
    "\n",
    "                        band = np.where((ipfreq >= B[0]) & (ipfreq < B[1]))\n",
    "\n",
    "                        ipfreq = np.take(ipfreq,band)[0]\n",
    "                        ipmag = np.take(ipmag,band)[0]\n",
    "                        ipphase = np.take(ipphase,band)[0]\n",
    "\n",
    "                        ipfreqTotal = np.append(ipfreqTotal,ipfreq)\n",
    "                        ipmagTotal = np.append(ipmagTotal,ipmag)\n",
    "                        ipphaseTotal = np.append(ipphaseTotal,ipphase)\n",
    "\n",
    "                Y = UF.genSpecSines(ipfreqTotal,ipmagTotal,ipphaseTotal,Ns,fs)\n",
    "                fftbuffer = np.real(ifft(Y))\n",
    "                yw[:hNs-1] = fftbuffer[hNs+1:]                        # undo zero-phase window\n",
    "                yw[hNs-1:] = fftbuffer[:hNs+1]\n",
    "                y[pin-hNs:pin+hNs] += sw*yw                           # overlap-add and apply a synthesis window\n",
    "                pin += H                                              # advance sound pointer\n",
    "\n",
    "        return y\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
